{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subsequent-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display, HTML\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "# Fix the dying kernel problem (only a problem in some installations - you can remove it, if it works without it)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-worse",
   "metadata": {},
   "source": [
    "# Load the dataset for recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "executive-terrace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>term</th>\n",
       "      <th>length_of_stay_bucket</th>\n",
       "      <th>rate_plan</th>\n",
       "      <th>room_segment</th>\n",
       "      <th>n_people_bucket</th>\n",
       "      <th>weekend_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Easter</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[8-inf]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = os.path.join(\"data\", \"hotel_data\")\n",
    "\n",
    "interactions_df = pd.read_csv(os.path.join(data_path, \"hotel_data_interactions_df.csv\"), index_col=0)\n",
    "\n",
    "base_item_features = ['term', 'length_of_stay_bucket', 'rate_plan', 'room_segment', 'n_people_bucket', 'weekend_stay']\n",
    "\n",
    "column_values_dict = {\n",
    "    'term': ['WinterVacation', 'Easter', 'OffSeason', 'HighSeason', 'LowSeason', 'MayLongWeekend', 'NewYear', 'Christmas'],\n",
    "    'length_of_stay_bucket': ['[0-1]', '[2-3]', '[4-7]', '[8-inf]'],\n",
    "    'rate_plan': ['Standard', 'Nonref'],\n",
    "    'room_segment': ['[0-160]', '[160-260]', '[260-360]', '[360-500]', '[500-900]'],\n",
    "    'n_people_bucket': ['[1-1]', '[2-2]', '[3-4]', '[5-inf]'],\n",
    "    'weekend_stay': ['True', 'False']\n",
    "}\n",
    "\n",
    "interactions_df.loc[:, 'term'] = pd.Categorical(\n",
    "    interactions_df['term'], categories=column_values_dict['term'])\n",
    "interactions_df.loc[:, 'length_of_stay_bucket'] = pd.Categorical(\n",
    "    interactions_df['length_of_stay_bucket'], categories=column_values_dict['length_of_stay_bucket'])\n",
    "interactions_df.loc[:, 'rate_plan'] = pd.Categorical(\n",
    "    interactions_df['rate_plan'], categories=column_values_dict['rate_plan'])\n",
    "interactions_df.loc[:, 'room_segment'] = pd.Categorical(\n",
    "    interactions_df['room_segment'], categories=column_values_dict['room_segment'])\n",
    "interactions_df.loc[:, 'n_people_bucket'] = pd.Categorical(\n",
    "    interactions_df['n_people_bucket'], categories=column_values_dict['n_people_bucket'])\n",
    "interactions_df.loc[:, 'weekend_stay'] = interactions_df['weekend_stay'].astype('str')\n",
    "interactions_df.loc[:, 'weekend_stay'] = pd.Categorical(\n",
    "    interactions_df['weekend_stay'], categories=column_values_dict['weekend_stay'])\n",
    "\n",
    "display(HTML(interactions_df.head(15).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "soviet-return",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>uf00</th>\n",
       "      <th>uf01</th>\n",
       "      <th>uf02</th>\n",
       "      <th>uf03</th>\n",
       "      <th>uf04</th>\n",
       "      <th>uf05</th>\n",
       "      <th>uf06</th>\n",
       "      <th>uf07</th>\n",
       "      <th>uf10</th>\n",
       "      <th>uf11</th>\n",
       "      <th>uf12</th>\n",
       "      <th>uf13</th>\n",
       "      <th>uf20</th>\n",
       "      <th>uf21</th>\n",
       "      <th>uf30</th>\n",
       "      <th>uf31</th>\n",
       "      <th>uf32</th>\n",
       "      <th>uf33</th>\n",
       "      <th>uf34</th>\n",
       "      <th>uf40</th>\n",
       "      <th>uf41</th>\n",
       "      <th>uf42</th>\n",
       "      <th>uf43</th>\n",
       "      <th>uf50</th>\n",
       "      <th>uf51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>50</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>96</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>115</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>706</td>\n",
       "      <td>0.091988</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.451039</td>\n",
       "      <td>0.189911</td>\n",
       "      <td>0.207715</td>\n",
       "      <td>0.038576</td>\n",
       "      <td>0.011869</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.169139</td>\n",
       "      <td>0.459941</td>\n",
       "      <td>0.272997</td>\n",
       "      <td>0.097923</td>\n",
       "      <td>0.994065</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.014837</td>\n",
       "      <td>0.851632</td>\n",
       "      <td>0.127596</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.041543</td>\n",
       "      <td>0.094955</td>\n",
       "      <td>0.738872</td>\n",
       "      <td>0.124629</td>\n",
       "      <td>0.676558</td>\n",
       "      <td>0.323442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>1736</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.551724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7639</th>\n",
       "      <td>7779</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.185185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def prepare_users_df(interactions_df):\n",
    "\n",
    "    # Write your code here\n",
    "    interactions_categories = interactions_df.loc[:,['term','length_of_stay_bucket','rate_plan','room_segment','n_people_bucket','weekend_stay']]\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "    ohe.fit(interactions_categories)\n",
    "    \n",
    "    interactions_user_categories = interactions_df.loc[:,['user_id','term','length_of_stay_bucket','rate_plan','room_segment','n_people_bucket','weekend_stay']]\n",
    "\n",
    "    user_occurences = interactions_user_categories.groupby(\"user_id\").count().sort_values(by=\"user_id\")\n",
    "\n",
    "    \n",
    "\n",
    "    all_cols = list(interactions_user_categories.columns)\n",
    "    all_cols.remove(\"user_id\")\n",
    "\n",
    "    main_users_df = pd.DataFrame()\n",
    "    for i,elem in enumerate(all_cols):\n",
    "        tmp_interactions_categories = interactions_user_categories.loc[:,[\"user_id\",elem]]\n",
    "        tmp_interactions_categories.loc[:,\"ones\"]=1\n",
    "        tmp_pivot = pd.pivot_table(tmp_interactions_categories,index=\"user_id\",columns=elem,values=\"ones\",aggfunc=np.sum,fill_value=-1)\n",
    "\n",
    "        tmp_pivot.columns=[\"uf\"+str(i)+str(k) for k in range(len(column_values_dict.get(elem)))]\n",
    "\n",
    "        if i==0:\n",
    "            main_users_df=tmp_pivot\n",
    "        else:\n",
    "            main_users_df=pd.merge(main_users_df,tmp_pivot,on=[\"user_id\"],how='left')\n",
    "        \n",
    "    main_users_df = main_users_df.apply(lambda x:(x/user_occurences['term']))\n",
    "    main_users_df=main_users_df.fillna(-1)\n",
    "    main_users_df[main_users_df==0.0]=-1\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "    users_df = main_users_df.reset_index().sort_values(by=\"user_id\",ascending=True)\n",
    "\n",
    "\n",
    "    user_features = list(users_df.columns)\n",
    "    user_features.remove(\"user_id\")\n",
    "    \n",
    "    return users_df, user_features\n",
    "    \n",
    "\n",
    "users_df, user_features = prepare_users_df(interactions_df)\n",
    "\n",
    "display(HTML(users_df.loc[users_df['user_id'].isin([706, 1736, 7779, 96, 1, 50, 115])].head(30).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fewer-partner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>if00</th>\n",
       "      <th>if01</th>\n",
       "      <th>if02</th>\n",
       "      <th>if03</th>\n",
       "      <th>if04</th>\n",
       "      <th>if05</th>\n",
       "      <th>if06</th>\n",
       "      <th>if07</th>\n",
       "      <th>if10</th>\n",
       "      <th>if11</th>\n",
       "      <th>if12</th>\n",
       "      <th>if13</th>\n",
       "      <th>if20</th>\n",
       "      <th>if21</th>\n",
       "      <th>if30</th>\n",
       "      <th>if31</th>\n",
       "      <th>if32</th>\n",
       "      <th>if33</th>\n",
       "      <th>if34</th>\n",
       "      <th>if40</th>\n",
       "      <th>if41</th>\n",
       "      <th>if42</th>\n",
       "      <th>if43</th>\n",
       "      <th>if50</th>\n",
       "      <th>if51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "def prepare_items_df(interactions_df):\n",
    "    cols = ['item_id','term','length_of_stay_bucket','rate_plan','room_segment','n_people_bucket','weekend_stay']\n",
    "    cats = []\n",
    "    if 'if11' not in cols:\n",
    "        cats = ['term','length_of_stay_bucket','rate_plan','room_segment','n_people_bucket','weekend_stay']\n",
    "   \n",
    "        interactions_item_categories = interactions_df.loc[:,cols]\n",
    "\n",
    "        item_occurences = interactions_item_categories.groupby(\"item_id\").count().sort_values(by=\"item_id\")\n",
    "\n",
    "        all_cols = list(interactions_item_categories.columns)\n",
    "        all_cols.remove(\"item_id\")\n",
    "\n",
    "        main_items_df = pd.DataFrame()\n",
    "        for i,elem in enumerate(all_cols):\n",
    "            tmp_interactions_categories = interactions_item_categories.loc[:,[\"item_id\",elem]]\n",
    "\n",
    "            tmp_interactions_categories.loc[:,\"ones\"]=1\n",
    "            tmp_pivot = pd.pivot_table(tmp_interactions_categories,index=\"item_id\",columns=elem,values=\"ones\",aggfunc=lambda x:1,fill_value=0.0)            \n",
    "            if len(tmp_pivot.columns)!=len(column_values_dict.get(elem)):\n",
    "                diff = set(column_values_dict.get(elem))-set(tmp_pivot.columns)\n",
    "                for ii in list(diff):\n",
    "                    tmp_pivot.loc[:,ii]=0.0\n",
    "\n",
    "            tmp_pivot.columns=[\"if\"+str(i)+str(k) for k in range(len(column_values_dict.get(elem)))]\n",
    "\n",
    "            if i==0:\n",
    "                main_items_df=tmp_pivot\n",
    "            else:\n",
    "                main_items_df=pd.merge(main_items_df,tmp_pivot,on=[\"item_id\"],how='left')\n",
    "\n",
    "        items_df = main_items_df.reset_index().sort_values(by=\"item_id\",ascending=True)\n",
    "\n",
    "    else:\n",
    "        items_df = interactions_df\n",
    "    items_df = items_df.fillna(0.0)\n",
    "    \n",
    "    item_features = list(items_df.columns)\n",
    "    item_features.remove(\"item_id\")\n",
    "    \n",
    "    return items_df.loc[:,[\"item_id\"]+item_features], item_features\n",
    "\n",
    "\n",
    "items_df, item_features = prepare_items_df(interactions_df)\n",
    "\n",
    "display(HTML(items_df.loc[items_df['item_id'].isin([0, 1, 2, 3, 4, 5, 6])].head(15).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-cursor",
   "metadata": {},
   "source": [
    "# (Optional) Prepare numerical user features\n",
    "\n",
    "The method below is left here for convenience if you want to experiment with content-based user features as an input for your neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_to_p(l):\n",
    "    n = sum(l)\n",
    "    return [x / n for x in l] if n > 0 else l\n",
    "\n",
    "def calculate_p(x, values):\n",
    "    counts = [0]*len(values)\n",
    "    for v in x:\n",
    "        counts[values.index(v)] += 1\n",
    "\n",
    "    return n_to_p(counts)\n",
    "\n",
    "def prepare_users_df(interactions_df):\n",
    "\n",
    "    users_df = interactions_df.loc[:, [\"user_id\"]]\n",
    "    users_df = users_df.groupby(\"user_id\").first().reset_index(drop=False)\n",
    "    \n",
    "    user_features = []\n",
    "\n",
    "    for column in base_item_features:\n",
    "\n",
    "        column_values = column_values_dict[column]\n",
    "        df = interactions_df.loc[:, ['user_id', column]]\n",
    "        df = df.groupby('user_id').aggregate(lambda x: list(x)).reset_index(drop=False)\n",
    "\n",
    "        def calc_p(x):\n",
    "            return calculate_p(x, column_values)\n",
    "\n",
    "        df.loc[:, column] = df[column].apply(lambda x: calc_p(x))\n",
    "\n",
    "        p_columns = []\n",
    "        for i in range(len(column_values)):\n",
    "            p_columns.append(\"user_\" + column + \"_\" + column_values[i])\n",
    "            df.loc[:, p_columns[i]] = df[column].apply(lambda x: x[i])\n",
    "            user_features.append(p_columns[i])\n",
    "\n",
    "        users_df = pd.merge(users_df, df.loc[:, ['user_id'] + p_columns], on=[\"user_id\"])\n",
    "    \n",
    "    return users_df, user_features\n",
    "    \n",
    "\n",
    "users_df, user_features = prepare_users_df(interactions_df)\n",
    "\n",
    "print(user_features)\n",
    "\n",
    "display(HTML(users_df.loc[users_df['user_id'].isin([706, 1736, 7779, 96, 1, 50, 115])].head(15).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-buddy",
   "metadata": {},
   "source": [
    "# (Optional) Prepare numerical item features\n",
    "\n",
    "The method below is left here for convenience if you want to experiment with content-based item features as an input for your neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-sleeve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_items_to_onehot(df):\n",
    "    one_hot = pd.get_dummies(df.loc[:, base_item_features])\n",
    "    df = df.drop(base_item_features, axis = 1)\n",
    "    df = df.join(one_hot)\n",
    "    \n",
    "    return df, list(one_hot.columns)\n",
    "\n",
    "def prepare_items_df(interactions_df):\n",
    "    items_df = interactions_df.loc[:, [\"item_id\"] + base_item_features].drop_duplicates()\n",
    "    \n",
    "    items_df, item_features = map_items_to_onehot(items_df)\n",
    "    \n",
    "    return items_df, item_features\n",
    "\n",
    "\n",
    "items_df, item_features = prepare_items_df(interactions_df)\n",
    "\n",
    "print(item_features)\n",
    "\n",
    "display(HTML(items_df.loc[items_df['item_id'].isin([0, 1, 2, 3, 4, 5, 6])].head(15).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-latino",
   "metadata": {},
   "source": [
    "# Neural network recommender\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Code a recommender based on a neural network model. You are free to choose any network architecture you find appropriate. The network can use the interaction vectors for users and items, embeddings of users and items, as well as user and item features (you can use the features you developed in the first project).\n",
    "\n",
    "Remember to keep control over randomness - in the init method add the seed as a parameter and initialize the random seed generator with that seed (both for numpy and pytorch):\n",
    "\n",
    "```python\n",
    "self.seed = seed\n",
    "self.rng = np.random.RandomState(seed=seed)\n",
    "```\n",
    "in the network model:\n",
    "```python\n",
    "self.seed = torch.manual_seed(seed)\n",
    "```\n",
    "\n",
    "You are encouraged to experiment with:\n",
    "  - the number of layers in the network, the number of neurons and different activation functions,\n",
    "  - different optimizers and their parameters,\n",
    "  - batch size and the number of epochs,\n",
    "  - embedding layers,\n",
    "  - content-based features of both users and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "afraid-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.recommender import Recommender\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "\n",
    "from recommenders.recommender import Recommender\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression,f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self, n_elems, embedding_dim, seed):\n",
    "        super().__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "\n",
    "        self.norm = nn.BatchNorm1d(27,affine=False)\n",
    "        self.cos = nn.CosineSimilarity()\n",
    "        self.fc1 = nn.Linear(n_elems, 64, bias=True)\n",
    "        self.fc2 = nn.Linear(64, 64, bias=False)\n",
    "        self.fc4 = nn.Linear(64, 16, bias=False)\n",
    "        self.fc6 = nn.Linear(16, 1, bias=False)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        vec1 = x[0,:,:]\n",
    "        vec2 = x[1,:,:]\n",
    "\n",
    "        vec3 = vec1*vec2\n",
    "        dot = torch.unsqueeze(torch.sum(vec3,dim=1),1)\n",
    "        sim = torch.unsqueeze(self.cos(vec1,vec2),1)\n",
    "        x = torch.cat([vec3,dot,sim],dim=1)\n",
    "        x = self.norm(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "\n",
    "        x = torch.relu(self.fc4(x))\n",
    "\n",
    "        x = torch.sigmoid(self.fc6(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class NNRecommender(Recommender):\n",
    "    \"\"\"\n",
    "    Linear recommender class based on user and item features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed=6789, n_neg_per_pos=5):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.model = None\n",
    "        self.n_neg_per_pos = n_neg_per_pos\n",
    "        \n",
    "        self.recommender_df = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        self.users_df = None\n",
    "        self.user_features = None\n",
    "        \n",
    "        self.seed = seed\n",
    "        self.rng = np.random.RandomState(seed=seed)\n",
    "        self.network = None\n",
    "        self.model_features = None\n",
    "        \n",
    "\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        \n",
    "        interactions_df = interactions_df.copy()\n",
    "        interactions_df.loc[:,\"interacted\"] = 1\n",
    "        \n",
    "        # Prepare users_df and items_df \n",
    "        # (optional - use only if you want to train a hybrid model with content-based features)\n",
    "        \n",
    "        users_df, user_features = prepare_users_df(interactions_df)\n",
    "        \n",
    "        self.users_df = users_df\n",
    "        self.user_features = user_features\n",
    "        \n",
    "        items_df, item_features = prepare_items_df(interactions_df)\n",
    "        items_df = items_df.loc[:, ['item_id'] + item_features]\n",
    "        \n",
    "        # Generate negative interactions\n",
    "        \n",
    "        # <<<Write your code here>>>\n",
    "        negative_interactions = []\n",
    "        \n",
    "        items_unique = interactions_df.loc[:,\"item_id\"].unique()\n",
    "        users_unique = interactions_df.loc[:,\"user_id\"].unique()\n",
    "\n",
    "        desire=int(self.n_neg_per_pos * len(interactions_df))\n",
    "        hmany=100\n",
    "        rng = np.random.RandomState(seed=6789)\n",
    "        real_interaction = interactions_df.loc[:,[\"user_id\",\"item_id\"]]\n",
    "        length = 0\n",
    "        total_negative_interactions=pd.DataFrame(negative_interactions)\n",
    "        while length!=desire and length<desire :\n",
    "            it = rng.choice(items_unique,hmany)\n",
    "            us = rng.choice(users_unique,hmany)\n",
    "            tmp_negative_interaction = pd.DataFrame({'user_id':us,'item_id':it}).drop_duplicates()\n",
    "\n",
    "            result = pd.merge(tmp_negative_interaction,real_interaction,on=[\"user_id\",\"item_id\"])\n",
    "            if len(result)==0:\n",
    "                total_negative_interactions = pd.concat([total_negative_interactions,tmp_negative_interaction]).drop_duplicates()\n",
    "                length = total_negative_interactions.size\n",
    "\n",
    "        total_negative_interactions = total_negative_interactions.iloc[:desire]\n",
    "        total_negative_interactions.loc[:,'interacted']=0\n",
    "        negative_interactions = total_negative_interactions.to_numpy()        \n",
    "        \n",
    "        interactions_df = pd.concat(\n",
    "            [interactions_df, pd.DataFrame(negative_interactions, columns=['user_id', 'item_id', 'interacted'])])\n",
    "        \n",
    "        # Merge user and item features\n",
    "        # (optional - use only if you want to train a hybrid model with content-based features)\n",
    "        \n",
    "        interactions_df = pd.merge(interactions_df, users_df, on=['user_id'])\n",
    "        interactions_df = pd.merge(interactions_df, items_df, on=['item_id'])\n",
    "        \n",
    "        \n",
    "        interactions_df = interactions_df.drop_duplicates()\n",
    "        \n",
    "        u_colls = users_df.columns.tolist()\n",
    "        u_colls.remove(\"user_id\")\n",
    "        i_colls = items_df.columns.tolist()\n",
    "        i_colls.remove(\"item_id\")\n",
    "\n",
    "        prod_cols = u_colls + i_colls\n",
    "\n",
    "    \n",
    "        new_interactions_df = interactions_df\n",
    "#         display(HTML(new_interactions_df.head(10).to_html()))\n",
    "        \n",
    "        self.model_features = prod_cols\n",
    "\n",
    "        x = new_interactions_df.loc[:,self.model_features]\n",
    "        y = new_interactions_df['interacted'].to_frame()\n",
    "        \n",
    "#         interaction_ids = self.rng.permutation(len(x))\n",
    "#         limit_id = int(0.2*len(interaction_ids))\n",
    "#         validation_ids = interaction_ids[:limit_id]\n",
    "        \n",
    "#         train_ids = interaction_ids[limit_id:]\n",
    "\n",
    "#         x_train = torch.tensor([(x.iloc[train_ids].loc[:,u_colls].to_numpy()),(x.iloc[train_ids].loc[:,i_colls].to_numpy())]).float()\n",
    "#         y_train = torch.tensor(y.iloc[train_ids].to_numpy()).float()\n",
    "#         x_val= torch.tensor([(x.iloc[validation_ids].loc[:,u_colls].to_numpy()),(x.iloc[validation_ids].loc[:,i_colls].to_numpy())]).float()\n",
    "\n",
    "#         y_val = torch.tensor(y.iloc[validation_ids].to_numpy()).float()\n",
    "        \n",
    "        x_train = torch.tensor([(x.loc[:,u_colls].to_numpy()),(x.loc[:,i_colls].to_numpy())]).float()\n",
    "        y_train = torch.tensor(y.to_numpy()).float()\n",
    "\n",
    "\n",
    "        # Initialize the neural network model\n",
    "        print(x_train.shape[1])\n",
    "        \n",
    "#         # <<<Write your code here>>>\n",
    "        self.network = MyNetwork(27,16,6789)\n",
    "#         \n",
    "        self.optimizer = optim.Adam(self.network.parameters(),lr = 0.00001)\n",
    "#         self.optimizer = optim.SGD(self.network.parameters(),lr = 0.000173)     \n",
    "#         self.optimizer = optim.SGD(self.network.parameters(),lr = 0.00001) \n",
    "#         self.optimizer = optim.Adadelta(self.network.parameters(),lr=0.01) \n",
    "        \n",
    "        # Train the model using an optimizer\n",
    "\n",
    "        min_loss = 100\n",
    "        epochs = 336\n",
    "\n",
    "        batch_size = 512\n",
    "        n_batches = int(np.ceil((x_train.shape[1])/batch_size))\n",
    "        for epoch in range(epochs):\n",
    "            for batch in range(n_batches):\n",
    "\n",
    "                x_tmp = x_train[:,(batch*batch_size):((batch+1)*batch_size),:]\n",
    "                y_tmp = y_train[(batch*batch_size):((batch+1)*batch_size) ]\n",
    "                self.network.train()\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                y_hat_train = self.network(x_tmp).clip(0.000001, 0.999999)\n",
    "\n",
    "                loss = - ((y_tmp * y_hat_train.log()) + ((1 - y_tmp) * (1-y_hat_train).log())).sum()\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "#                 self.network.eval()\n",
    "#                 with torch.no_grad():\n",
    "                    \n",
    "#                     y_hat_val = self.network(x_val).clip(0.000001, 0.999999)\n",
    "\n",
    "#                     print(\"MAX: \",torch.where((y_val-y_hat_val).abs()>0.5,1.0,0.0).sum())\n",
    "\n",
    "#                     loss_val = - ((y_val * y_hat_val.log()) + ((1 - y_val) * (1-y_hat_val).log()) ).sum()\n",
    "#                     if min_loss>loss_val.item():\n",
    "#                         min_loss = loss_val.item()\n",
    "\n",
    "#                     print(epoch,\" :: \",loss_val)\n",
    "\n",
    "                \n",
    "            \n",
    "        \n",
    "        # <<<Write your code here>>>\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        # Clean previous recommendations (iloc could be used alternatively)\n",
    "        self.recommender_df = self.recommender_df[:0]\n",
    "        \n",
    "        # Prepare users_df and items_df\n",
    "        # (optional - use only if you want to train a hybrid model with content-based features)\n",
    "        \n",
    "        users_df = users_df.loc[:, 'user_id']\n",
    "        users_df = pd.merge(users_df, self.users_df, on=['user_id'], how='left').fillna(0)\n",
    "\n",
    "        \n",
    "        items_df, item_features = prepare_items_df(items_df)\n",
    "        items_df = items_df.loc[:, ['item_id'] + item_features]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Score the items\n",
    "    \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "\n",
    "        for ix, user in users_df.iterrows():\n",
    "            \n",
    "            # Calculate the score for the user and every item in items_df\n",
    "            interactions_df = pd.merge(user.to_frame().transpose(),items_df,how=\"cross\")\n",
    "\n",
    "            \n",
    "            u_colls = users_df.columns.tolist()\n",
    "            u_colls.remove(\"user_id\")\n",
    "            i_colls = items_df.columns.tolist()\n",
    "            i_colls.remove(\"item_id\")\n",
    "\n",
    "\n",
    "            prod_cols=[]\n",
    "\n",
    "\n",
    "            interactions_df = interactions_df.fillna(0)\n",
    "\n",
    "            scaled_df = interactions_df.loc[:,self.model_features]\n",
    "            \n",
    "\n",
    "            x = scaled_df.loc[:,self.model_features]\n",
    "            x_test = torch.tensor([(x.loc[:,u_colls].to_numpy()),(x.loc[:,i_colls].to_numpy())]).float()\n",
    "            \n",
    "\n",
    "            self.network.eval()\n",
    "            with torch.no_grad():\n",
    "                out = self.network(x_test)\n",
    "\n",
    "            \n",
    "            scores = out.squeeze().numpy()\n",
    "\n",
    "            chosen_ids = np.argsort(-scores)[:n_recommendations].tolist()\n",
    "\n",
    "            scores = scores.tolist()\n",
    "            \n",
    "            recommendations = []\n",
    "            for item_id in chosen_ids:\n",
    "                recommendations.append(\n",
    "                    {\n",
    "                        'user_id': user['user_id'],\n",
    "                        'item_id': item_id,\n",
    "                        'score': scores[item_id]\n",
    "                    }\n",
    "                )\n",
    "            user_recommendations = pd.DataFrame(recommendations)\n",
    "\n",
    "            self.recommender_df = pd.concat([self.recommender_df, user_recommendations])\n",
    "\n",
    "        return self.recommender_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-daughter",
   "metadata": {},
   "source": [
    "# Quick test of the recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dominican-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = interactions_df.loc[:, ['item_id'] + base_item_features].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "short-smith",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55952\n"
     ]
    }
   ],
   "source": [
    "# Fit method\n",
    "nn_recommender = NNRecommender()\n",
    "nn_recommender.fit(interactions_df, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "nutritional-touch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>term</th>\n",
       "      <th>length_of_stay_bucket</th>\n",
       "      <th>rate_plan</th>\n",
       "      <th>room_segment</th>\n",
       "      <th>n_people_bucket</th>\n",
       "      <th>weekend_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.996840</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.997019</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>98</td>\n",
       "      <td>0.997121</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.997203</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.997267</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.997479</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>108</td>\n",
       "      <td>0.998096</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.998161</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>102</td>\n",
       "      <td>0.998470</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>0.998566</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.897780</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>87</td>\n",
       "      <td>0.910808</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.923585</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>208</td>\n",
       "      <td>0.936583</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0.937967</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.951299</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>159</td>\n",
       "      <td>0.980404</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>68</td>\n",
       "      <td>0.983061</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.997676</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999097</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.0</td>\n",
       "      <td>87</td>\n",
       "      <td>0.921509</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.935450</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.0</td>\n",
       "      <td>73</td>\n",
       "      <td>0.947161</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.0</td>\n",
       "      <td>68</td>\n",
       "      <td>0.956431</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.0</td>\n",
       "      <td>279</td>\n",
       "      <td>0.963534</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.0</td>\n",
       "      <td>168</td>\n",
       "      <td>0.964884</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.0</td>\n",
       "      <td>56</td>\n",
       "      <td>0.972287</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>174</td>\n",
       "      <td>0.972518</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.983929</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999268</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4.0</td>\n",
       "      <td>116</td>\n",
       "      <td>0.875288</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0.883923</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.897170</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.919180</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.925251</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.928072</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.971151</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4.0</td>\n",
       "      <td>54</td>\n",
       "      <td>0.972795</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.0</td>\n",
       "      <td>77</td>\n",
       "      <td>0.995095</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.998240</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.0</td>\n",
       "      <td>133</td>\n",
       "      <td>0.534986</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.0</td>\n",
       "      <td>61</td>\n",
       "      <td>0.655761</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.0</td>\n",
       "      <td>687</td>\n",
       "      <td>0.730977</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0.759022</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5.0</td>\n",
       "      <td>77</td>\n",
       "      <td>0.850812</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.0</td>\n",
       "      <td>497</td>\n",
       "      <td>0.864257</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.0</td>\n",
       "      <td>565</td>\n",
       "      <td>0.895590</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5.0</td>\n",
       "      <td>89</td>\n",
       "      <td>0.899084</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5.0</td>\n",
       "      <td>87</td>\n",
       "      <td>0.936536</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.993562</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Recommender method\n",
    "\n",
    "recommendations = nn_recommender.recommend(pd.DataFrame([[1], [2], [3], [4], [5]], columns=['user_id']), items_df, 10)\n",
    "\n",
    "recommendations = pd.merge(recommendations, items_df, on='item_id', how='left')\n",
    "display(HTML(recommendations.sort_values(by=[\"user_id\",\"score\"],ascending=True).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-presence",
   "metadata": {},
   "source": [
    "# Tuning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "blank-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_and_testing.testing import evaluate_train_test_split_implicit\n",
    "\n",
    "seed = 6789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "closing-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "import traceback\n",
    "\n",
    "def tune_recommender(recommender_class, interactions_df, items_df, \n",
    "                     param_space, max_evals=1, show_progressbar=True, seed=6789):\n",
    "    # Split into train_validation and test sets\n",
    "\n",
    "    shuffle = np.arange(len(interactions_df))\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    rng.shuffle(shuffle)\n",
    "    shuffle = list(shuffle)\n",
    "\n",
    "    train_test_split = 0.8\n",
    "    split_index = int(len(interactions_df) * train_test_split)\n",
    "\n",
    "    train_validation = interactions_df.iloc[shuffle[:split_index]]\n",
    "    test = interactions_df.iloc[shuffle[split_index:]]\n",
    "\n",
    "    # Tune\n",
    "\n",
    "    def loss(tuned_params):\n",
    "        recommender = recommender_class(seed=seed, **tuned_params)\n",
    "        hr1, hr3, hr5, hr10, ndcg1, ndcg3, ndcg5, ndcg10 = evaluate_train_test_split_implicit(\n",
    "            recommender, train_validation, items_df, seed=seed)\n",
    "        return -hr10\n",
    "\n",
    "    n_tries = 1\n",
    "    succeded = False\n",
    "    try_id = 0\n",
    "    while not succeded and try_id < n_tries:\n",
    "        try:\n",
    "            trials = Trials()\n",
    "            best_param_set = fmin(loss, space=param_space, algo=tpe.suggest, \n",
    "                                  max_evals=max_evals, show_progressbar=show_progressbar, trials=trials, verbose=True)\n",
    "            succeded = True\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            try_id += 1\n",
    "            \n",
    "    if not succeded:\n",
    "        return None\n",
    "        \n",
    "    # Validate\n",
    "    \n",
    "    recommender = recommender_class(seed=seed, **best_param_set)\n",
    "\n",
    "    results = [[recommender_class.__name__] + list(evaluate_train_test_split_implicit(\n",
    "        recommender, {'train': train_validation, 'test': test}, items_df, seed=seed))]\n",
    "\n",
    "    results = pd.DataFrame(results, \n",
    "                           columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "    display(HTML(results.to_html()))\n",
    "    \n",
    "    return best_param_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-nigeria",
   "metadata": {},
   "source": [
    "## Tuning of the recommender\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Tune your model using the code below. You only need to put the class name of your recommender and choose an appropriate parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "tutorial-burning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30728                                                 \n",
      "56491                                                                                \n",
      "25543                                                                                \n",
      "25543                                                                                \n",
      "15263                                                                              \n",
      "46159                                                                               \n",
      "56491                                                                               \n",
      "61654                                                                               \n",
      "46159                                                                                 \n",
      "56491                                                                                 \n",
      "100%|██████████| 10/10 [1:22:11<00:00, 493.20s/trial, best loss: -0.050389184760344125]\n",
      "19042\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NNRecommender</td>\n",
       "      <td>0.018427</td>\n",
       "      <td>0.030931</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>0.056598</td>\n",
       "      <td>0.018427</td>\n",
       "      <td>0.025627</td>\n",
       "      <td>0.028884</td>\n",
       "      <td>0.034624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:\n",
      "{'n_neg_per_pos': 1.0}\n"
     ]
    }
   ],
   "source": [
    "param_space = {\n",
    "    'n_neg_per_pos': hp.quniform('n_neg_per_pos', 1, 10, 1)\n",
    "}\n",
    "\n",
    "best_param_set = tune_recommender(NNRecommender, interactions_df, items_df,\n",
    "                                  param_space, max_evals=10, show_progressbar=True, seed=seed)\n",
    "\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(best_param_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-procedure",
   "metadata": {},
   "source": [
    "# Final evaluation\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Run the final evaluation of your recommender and present its results against the Amazon and Netflix recommenders' results. You just need to give the class name of your recommender and its tuned parameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "narrow-productivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19042\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NNRecommender</td>\n",
       "      <td>0.018427</td>\n",
       "      <td>0.030931</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>0.056598</td>\n",
       "      <td>0.018427</td>\n",
       "      <td>0.025627</td>\n",
       "      <td>0.028884</td>\n",
       "      <td>0.034624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_recommender = NNRecommender(n_neg_per_pos=1)  # Initialize your recommender here\n",
    "\n",
    "# Give the name of your recommender in the line below\n",
    "nn_tts_results = [['NNRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    nn_recommender, interactions_df, items_df))]\n",
    "\n",
    "nn_tts_results = pd.DataFrame(\n",
    "    nn_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(nn_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "consistent-killer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmazonRecommender</td>\n",
       "      <td>0.04179</td>\n",
       "      <td>0.105298</td>\n",
       "      <td>0.141494</td>\n",
       "      <td>0.200066</td>\n",
       "      <td>0.04179</td>\n",
       "      <td>0.07712</td>\n",
       "      <td>0.092218</td>\n",
       "      <td>0.110992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from recommenders.amazon_recommender import AmazonRecommender\n",
    "\n",
    "amazon_recommender = AmazonRecommender()\n",
    "\n",
    "amazon_tts_results = [['AmazonRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    amazon_recommender, interactions_df, items_df))]\n",
    "\n",
    "amazon_tts_results = pd.DataFrame(\n",
    "    amazon_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(amazon_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "employed-guyana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss\n",
      "\ttraining         \t (min:    0.161, max:    0.220, cur:    0.161)\n",
      "\tvalidation       \t (min:    0.178, max:    0.237, cur:    0.179)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NetflixRecommender</td>\n",
       "      <td>0.04179</td>\n",
       "      <td>0.105956</td>\n",
       "      <td>0.143139</td>\n",
       "      <td>0.201382</td>\n",
       "      <td>0.04179</td>\n",
       "      <td>0.077535</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.11166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from recommenders.netflix_recommender import NetflixRecommender\n",
    "\n",
    "netflix_recommender = NetflixRecommender(n_epochs=30, print_type='live')\n",
    "\n",
    "netflix_tts_results = [['NetflixRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    netflix_recommender, interactions_df, items_df))]\n",
    "\n",
    "netflix_tts_results = pd.DataFrame(\n",
    "    netflix_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(netflix_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ethical-drain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NNRecommender</td>\n",
       "      <td>0.018427</td>\n",
       "      <td>0.030931</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>0.056598</td>\n",
       "      <td>0.018427</td>\n",
       "      <td>0.025627</td>\n",
       "      <td>0.028884</td>\n",
       "      <td>0.034624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmazonRecommender</td>\n",
       "      <td>0.041790</td>\n",
       "      <td>0.105298</td>\n",
       "      <td>0.141494</td>\n",
       "      <td>0.200066</td>\n",
       "      <td>0.041790</td>\n",
       "      <td>0.077120</td>\n",
       "      <td>0.092218</td>\n",
       "      <td>0.110992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NetflixRecommender</td>\n",
       "      <td>0.041790</td>\n",
       "      <td>0.105956</td>\n",
       "      <td>0.143139</td>\n",
       "      <td>0.201382</td>\n",
       "      <td>0.041790</td>\n",
       "      <td>0.077535</td>\n",
       "      <td>0.093015</td>\n",
       "      <td>0.111660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tts_results = pd.concat([nn_tts_results, amazon_tts_results, netflix_tts_results]).reset_index(drop=True)\n",
    "display(HTML(tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-acrylic",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Write a summary of your experiments. What worked well and what did not? What are your thoughts how could you possibly further improve the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "Normalizacja wektora oraz obliczenie podobieństwa cosinusowego zwiększyło dokładność modelu. Brak, chociażby normalizacji powodował problemy ze zbieganiem funkcji błędu do minimum.\n",
    "Większa ilość warstw ukrytych przyczyniała się do pojawienia się efektu przeuczenia (sieć za bardzo się upodabniała do przykładów treningowych)\n",
    "\n",
    "Moim zdaniem model można ulepszyć poprzez precyzyjniejsze dopracowanie wektorów usewrów i itemów. Ponadto rozbudowanie struktury sieci mogłoby również mieć pozytywny wpływ na dokładność rekomendacji.\n",
    "\n",
    "Można by również rozważyć 'zdynamizowanie' parametru learning rate. Być może zmiana jego wartości w trakcie uczenia na podstawie aktualnej wartości funkcji błędu mogłaby doprowadzić do szybszego osiągnięcia minimum."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
