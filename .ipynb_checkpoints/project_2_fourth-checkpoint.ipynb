{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "preliminary-precipitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display, HTML\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "# Fix the dying kernel problem (only a problem in some installations - you can remove it, if it works without it)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-diabetes",
   "metadata": {},
   "source": [
    "# Load the dataset for recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gross-focus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>term</th>\n",
       "      <th>length_of_stay_bucket</th>\n",
       "      <th>rate_plan</th>\n",
       "      <th>room_segment</th>\n",
       "      <th>n_people_bucket</th>\n",
       "      <th>weekend_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Easter</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[1-1]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[8-inf]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = os.path.join(\"data\", \"hotel_data\")\n",
    "\n",
    "interactions_df = pd.read_csv(os.path.join(data_path, \"hotel_data_interactions_df.csv\"), index_col=0)\n",
    "\n",
    "base_item_features = ['term', 'length_of_stay_bucket', 'rate_plan', 'room_segment', 'n_people_bucket', 'weekend_stay']\n",
    "\n",
    "column_values_dict = {\n",
    "    'term': ['WinterVacation', 'Easter', 'OffSeason', 'HighSeason', 'LowSeason', 'MayLongWeekend', 'NewYear', 'Christmas'],\n",
    "    'length_of_stay_bucket': ['[0-1]', '[2-3]', '[4-7]', '[8-inf]'],\n",
    "    'rate_plan': ['Standard', 'Nonref'],\n",
    "    'room_segment': ['[0-160]', '[160-260]', '[260-360]', '[360-500]', '[500-900]'],\n",
    "    'n_people_bucket': ['[1-1]', '[2-2]', '[3-4]', '[5-inf]'],\n",
    "    'weekend_stay': ['True', 'False']\n",
    "}\n",
    "\n",
    "interactions_df.loc[:, 'term'] = pd.Categorical(\n",
    "    interactions_df['term'], categories=column_values_dict['term'])\n",
    "interactions_df.loc[:, 'length_of_stay_bucket'] = pd.Categorical(\n",
    "    interactions_df['length_of_stay_bucket'], categories=column_values_dict['length_of_stay_bucket'])\n",
    "interactions_df.loc[:, 'rate_plan'] = pd.Categorical(\n",
    "    interactions_df['rate_plan'], categories=column_values_dict['rate_plan'])\n",
    "interactions_df.loc[:, 'room_segment'] = pd.Categorical(\n",
    "    interactions_df['room_segment'], categories=column_values_dict['room_segment'])\n",
    "interactions_df.loc[:, 'n_people_bucket'] = pd.Categorical(\n",
    "    interactions_df['n_people_bucket'], categories=column_values_dict['n_people_bucket'])\n",
    "interactions_df.loc[:, 'weekend_stay'] = interactions_df['weekend_stay'].astype('str')\n",
    "interactions_df.loc[:, 'weekend_stay'] = pd.Categorical(\n",
    "    interactions_df['weekend_stay'], categories=column_values_dict['weekend_stay'])\n",
    "\n",
    "display(HTML(interactions_df.head(15).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ambient-indianapolis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>uf00</th>\n",
       "      <th>uf01</th>\n",
       "      <th>uf02</th>\n",
       "      <th>uf03</th>\n",
       "      <th>uf04</th>\n",
       "      <th>uf05</th>\n",
       "      <th>uf06</th>\n",
       "      <th>uf07</th>\n",
       "      <th>uf10</th>\n",
       "      <th>uf11</th>\n",
       "      <th>uf12</th>\n",
       "      <th>uf13</th>\n",
       "      <th>uf20</th>\n",
       "      <th>uf21</th>\n",
       "      <th>uf30</th>\n",
       "      <th>uf31</th>\n",
       "      <th>uf32</th>\n",
       "      <th>uf33</th>\n",
       "      <th>uf34</th>\n",
       "      <th>uf40</th>\n",
       "      <th>uf41</th>\n",
       "      <th>uf42</th>\n",
       "      <th>uf43</th>\n",
       "      <th>uf50</th>\n",
       "      <th>uf51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>50</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>96</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>115</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>706</td>\n",
       "      <td>0.091988</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.451039</td>\n",
       "      <td>0.189911</td>\n",
       "      <td>0.207715</td>\n",
       "      <td>0.038576</td>\n",
       "      <td>0.011869</td>\n",
       "      <td>0.008902</td>\n",
       "      <td>0.169139</td>\n",
       "      <td>0.459941</td>\n",
       "      <td>0.272997</td>\n",
       "      <td>0.097923</td>\n",
       "      <td>0.994065</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>0.014837</td>\n",
       "      <td>0.851632</td>\n",
       "      <td>0.127596</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.041543</td>\n",
       "      <td>0.094955</td>\n",
       "      <td>0.738872</td>\n",
       "      <td>0.124629</td>\n",
       "      <td>0.676558</td>\n",
       "      <td>0.323442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>1736</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.172414</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.551724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7639</th>\n",
       "      <td>7779</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.185185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def prepare_users_df(interactions_df):\n",
    "\n",
    "    # Write your code here\n",
    "    interactions_categories = interactions_df.loc[:,['term','length_of_stay_bucket','rate_plan','room_segment','n_people_bucket','weekend_stay']]\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "    ohe.fit(interactions_categories)\n",
    "    \n",
    "    interactions_user_categories = interactions_df.loc[:,['user_id','term','length_of_stay_bucket','rate_plan','room_segment','n_people_bucket','weekend_stay']]\n",
    "\n",
    "    user_occurences = interactions_user_categories.groupby(\"user_id\").count().sort_values(by=\"user_id\")\n",
    "\n",
    "    \n",
    "\n",
    "    all_cols = list(interactions_user_categories.columns)\n",
    "    all_cols.remove(\"user_id\")\n",
    "\n",
    "    main_users_df = pd.DataFrame()\n",
    "    for i,elem in enumerate(all_cols):\n",
    "        tmp_interactions_categories = interactions_user_categories.loc[:,[\"user_id\",elem]]\n",
    "        tmp_interactions_categories.loc[:,\"ones\"]=1\n",
    "        tmp_pivot = pd.pivot_table(tmp_interactions_categories,index=\"user_id\",columns=elem,values=\"ones\",aggfunc=np.sum,fill_value=-1)\n",
    "\n",
    "        tmp_pivot.columns=[\"uf\"+str(i)+str(k) for k in range(len(column_values_dict.get(elem)))]\n",
    "\n",
    "        if i==0:\n",
    "            main_users_df=tmp_pivot\n",
    "        else:\n",
    "            main_users_df=pd.merge(main_users_df,tmp_pivot,on=[\"user_id\"],how='left')\n",
    "        \n",
    "    main_users_df = main_users_df.apply(lambda x:(x/user_occurences['term']))\n",
    "    main_users_df=main_users_df.fillna(-1.0)\n",
    "#     main_users_df[main_users_df<0.5]=0\n",
    "    main_users_df[main_users_df==0.0]=-1\n",
    "#     main_users_df[main_users_df>=0.5]=1\n",
    "    \n",
    "#     main_users_df = main_users_df.apply(lambda x:np.sin(x))\n",
    "    \n",
    "    \n",
    "#     display(HTML(main_users_df.head(20).to_html()))\n",
    "        \n",
    "    users_df = main_users_df.reset_index().sort_values(by=\"user_id\",ascending=True)\n",
    "#     display(HTML(users_df.head(20).to_html()))\n",
    "\n",
    "    user_features = list(users_df.columns)\n",
    "    user_features.remove(\"user_id\")\n",
    "    \n",
    "    return users_df, user_features\n",
    "    \n",
    "\n",
    "users_df, user_features = prepare_users_df(interactions_df)\n",
    "# display(HTML(interactions_df.head(20).to_html()))\n",
    "\n",
    "# print(user_features)\n",
    "# display(HTML(users_df[users_df==np.NAN].head(20).to_html()))\n",
    "display(HTML(users_df.loc[users_df['user_id'].isin([706, 1736, 7779, 96, 1, 50, 115])].head(30).to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "separate-mills",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>if00</th>\n",
       "      <th>if01</th>\n",
       "      <th>if02</th>\n",
       "      <th>if03</th>\n",
       "      <th>if04</th>\n",
       "      <th>if05</th>\n",
       "      <th>if06</th>\n",
       "      <th>if07</th>\n",
       "      <th>if10</th>\n",
       "      <th>if11</th>\n",
       "      <th>if12</th>\n",
       "      <th>if13</th>\n",
       "      <th>if20</th>\n",
       "      <th>if21</th>\n",
       "      <th>if30</th>\n",
       "      <th>if31</th>\n",
       "      <th>if32</th>\n",
       "      <th>if33</th>\n",
       "      <th>if34</th>\n",
       "      <th>if40</th>\n",
       "      <th>if41</th>\n",
       "      <th>if42</th>\n",
       "      <th>if43</th>\n",
       "      <th>if50</th>\n",
       "      <th>if51</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "def prepare_items_df(interactions_df):\n",
    "    cols = ['item_id','term','length_of_stay_bucket','rate_plan','room_segment','n_people_bucket','weekend_stay']\n",
    "    cats = []\n",
    "    if 'if11' not in cols:\n",
    "        cats = ['term','length_of_stay_bucket','rate_plan','room_segment','n_people_bucket','weekend_stay']\n",
    "   \n",
    "        interactions_item_categories = interactions_df.loc[:,cols]\n",
    "\n",
    "        item_occurences = interactions_item_categories.groupby(\"item_id\").count().sort_values(by=\"item_id\")\n",
    "\n",
    "        all_cols = list(interactions_item_categories.columns)\n",
    "        all_cols.remove(\"item_id\")\n",
    "\n",
    "        main_items_df = pd.DataFrame()\n",
    "        for i,elem in enumerate(all_cols):\n",
    "            tmp_interactions_categories = interactions_item_categories.loc[:,[\"item_id\",elem]]\n",
    "\n",
    "            tmp_interactions_categories.loc[:,\"ones\"]=1\n",
    "            tmp_pivot = pd.pivot_table(tmp_interactions_categories,index=\"item_id\",columns=elem,values=\"ones\",aggfunc=lambda x:1,fill_value=-1)            \n",
    "            if len(tmp_pivot.columns)!=len(column_values_dict.get(elem)):\n",
    "                diff = set(column_values_dict.get(elem))-set(tmp_pivot.columns)\n",
    "                for ii in list(diff):\n",
    "                    tmp_pivot.loc[:,ii]=-1\n",
    "\n",
    "            tmp_pivot.columns=[\"if\"+str(i)+str(k) for k in range(len(column_values_dict.get(elem)))]\n",
    "\n",
    "            if i==0:\n",
    "                main_items_df=tmp_pivot\n",
    "            else:\n",
    "                main_items_df=pd.merge(main_items_df,tmp_pivot,on=[\"item_id\"],how='left')\n",
    "\n",
    "        items_df = main_items_df.reset_index().sort_values(by=\"item_id\",ascending=True)\n",
    "\n",
    "    else:\n",
    "        items_df = interactions_df\n",
    "    items_df = items_df.fillna(-1)\n",
    "    \n",
    "    item_features = list(items_df.columns)\n",
    "    item_features.remove(\"item_id\")\n",
    "    \n",
    "    return items_df.loc[:,[\"item_id\"]+item_features], item_features\n",
    "\n",
    "\n",
    "items_df, item_features = prepare_items_df(interactions_df)\n",
    "\n",
    "display(HTML(items_df.loc[items_df['item_id'].isin([0, 1, 2, 3, 4, 5, 6])].head(15).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-appearance",
   "metadata": {},
   "source": [
    "# (Optional) Prepare numerical user features\n",
    "\n",
    "The method below is left here for convenience if you want to experiment with content-based user features as an input for your neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "suitable-convention",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "nan is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-79a89ba1fcad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0musers_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_users_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteractions_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-79a89ba1fcad>\u001b[0m in \u001b[0;36mprepare_users_df\u001b[0;34m(interactions_df)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcalculate_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcalc_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mp_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/REK/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4136\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4138\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-79a89ba1fcad>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcalculate_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcalc_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mp_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-79a89ba1fcad>\u001b[0m in \u001b[0;36mcalc_p\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcalc_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcalculate_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcalc_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-79a89ba1fcad>\u001b[0m in \u001b[0;36mcalculate_p\u001b[0;34m(x, values)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mcounts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mn_to_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: nan is not in list"
     ]
    }
   ],
   "source": [
    "def n_to_p(l):\n",
    "    n = sum(l)\n",
    "    return [x / n for x in l] if n > 0 else l\n",
    "\n",
    "def calculate_p(x, values):\n",
    "    counts = [0]*len(values)\n",
    "    for v in x:\n",
    "        counts[values.index(v)] += 1\n",
    "\n",
    "    return n_to_p(counts)\n",
    "\n",
    "def prepare_users_df(interactions_df):\n",
    "\n",
    "    users_df = interactions_df.loc[:, [\"user_id\"]]\n",
    "    users_df = users_df.groupby(\"user_id\").first().reset_index(drop=False)\n",
    "    \n",
    "    user_features = []\n",
    "\n",
    "    for column in base_item_features:\n",
    "\n",
    "        column_values = column_values_dict[column]\n",
    "        df = interactions_df.loc[:, ['user_id', column]]\n",
    "        df = df.groupby('user_id').aggregate(lambda x: list(x)).reset_index(drop=False)\n",
    "\n",
    "        def calc_p(x):\n",
    "            return calculate_p(x, column_values)\n",
    "\n",
    "        df.loc[:, column] = df[column].apply(lambda x: calc_p(x))\n",
    "\n",
    "        p_columns = []\n",
    "        for i in range(len(column_values)):\n",
    "            p_columns.append(\"user_\" + column + \"_\" + column_values[i])\n",
    "            df.loc[:, p_columns[i]] = df[column].apply(lambda x: x[i])\n",
    "            user_features.append(p_columns[i])\n",
    "\n",
    "        users_df = pd.merge(users_df, df.loc[:, ['user_id'] + p_columns], on=[\"user_id\"])\n",
    "    \n",
    "    return users_df, user_features\n",
    "    \n",
    "\n",
    "users_df, user_features = prepare_users_df(interactions_df)\n",
    "\n",
    "print(user_features)\n",
    "\n",
    "display(HTML(users_df.loc[users_df['user_id'].isin([706, 1736, 7779, 96, 1, 50, 115])].head(15).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-elevation",
   "metadata": {},
   "source": [
    "# (Optional) Prepare numerical item features\n",
    "\n",
    "The method below is left here for convenience if you want to experiment with content-based item features as an input for your neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_items_to_onehot(df):\n",
    "    one_hot = pd.get_dummies(df.loc[:, base_item_features])\n",
    "    df = df.drop(base_item_features, axis = 1)\n",
    "    df = df.join(one_hot)\n",
    "    \n",
    "    return df, list(one_hot.columns)\n",
    "\n",
    "def prepare_items_df(interactions_df):\n",
    "    items_df = interactions_df.loc[:, [\"item_id\"] + base_item_features].drop_duplicates()\n",
    "    \n",
    "    items_df, item_features = map_items_to_onehot(items_df)\n",
    "    \n",
    "    return items_df, item_features\n",
    "\n",
    "\n",
    "items_df, item_features = prepare_items_df(interactions_df)\n",
    "\n",
    "print(item_features)\n",
    "\n",
    "display(HTML(items_df.loc[items_df['item_id'].isin([0, 1, 2, 3, 4, 5, 6])].head(15).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-northern",
   "metadata": {},
   "source": [
    "# Neural network recommender\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Code a recommender based on a neural network model. You are free to choose any network architecture you find appropriate. The network can use the interaction vectors for users and items, embeddings of users and items, as well as user and item features (you can use the features you developed in the first project).\n",
    "\n",
    "Remember to keep control over randomness - in the init method add the seed as a parameter and initialize the random seed generator with that seed (both for numpy and pytorch):\n",
    "\n",
    "```python\n",
    "self.seed = seed\n",
    "self.rng = np.random.RandomState(seed=seed)\n",
    "```\n",
    "in the network model:\n",
    "```python\n",
    "self.seed = torch.manual_seed(seed)\n",
    "```\n",
    "\n",
    "You are encouraged to experiment with:\n",
    "  - the number of layers in the network, the number of neurons and different activation functions,\n",
    "  - different optimizers and their parameters,\n",
    "  - batch size and the number of epochs,\n",
    "  - embedding layers,\n",
    "  - content-based features of both users and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "israeli-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.recommender import Recommender\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n",
    "\n",
    "from recommenders.recommender import Recommender\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression,f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "\n",
    "class MyNetwork(nn.Module):\n",
    "#     def __init__(self, n_items, n_users, embedding_dim, seed):\n",
    "    def __init__(self, n_elems, embedding_dim, seed):\n",
    "        super().__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        \n",
    "#         self.u_colls = u_colls\n",
    "#         self.i_colls = i_colls\n",
    "#         self.elem_embedding = nn.Embedding(n_elems,embedding_dim)\n",
    "#         self.user_embedding = nn.Embeding(n_users,embedding_dim)\n",
    "        self.norm = nn.BatchNorm1d(27,affine=False)\n",
    "        self.cos = nn.CosineSimilarity()\n",
    "        self.fc1 = nn.Linear(n_elems, 64, bias=True)\n",
    "        self.fc2 = nn.Linear(64, 64, bias=False)\n",
    "#         self.fc3 = nn.Linear(64, 32, bias=False)\n",
    "#         self.fc3 = nn.Linear(128, 128, bias=False)\n",
    "        self.fc4 = nn.Linear(64, 16, bias=False)\n",
    "#         self.fc5 = nn.Linear(16, 4, bias=False)\n",
    "        self.fc6 = nn.Linear(16, 1, bias=False)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        vec1 = x[0,:,:]\n",
    "        vec2 = x[1,:,:]\n",
    "        \n",
    "#         print(\"VEC1 \",vec1.shape)\n",
    "#         print(\"VEC2 \",vec2.shape)\n",
    "#         print(\"X shape \",x.shape)\n",
    "#         elem_embedding = self.elem_embedding(x)\n",
    "#         print(\"elem_embedding shape \",elem_embedding.shape)\n",
    "#         item_embedding = self.item_embedding(item)1\n",
    "#         x = torch.cat([user_embedding, item_embedding], dim=1)\n",
    "#         vec1_norm = self.norm(vec1)\n",
    "#         print(\"NORM1 \",vec1_norm)\n",
    "#         vec2_norm = self.norm(vec2)\n",
    "        vec3 = vec1*vec2\n",
    "#         vec3 = vec1_norm*vec2_norm\n",
    "#         dot = torch.unsqueeze(vec3.sum(),1)\n",
    "        dot = torch.unsqueeze(torch.sum(vec3,dim=1),1)\n",
    "#         print(dot.shape)\n",
    "#         sim = torch.unsqueeze(self.cos(vec1,vec2),1)\n",
    "        sim = torch.unsqueeze(self.cos(vec1,vec2),1)\n",
    "#         print(sim.shape)\n",
    "#         vec3 = self.norm(vec3)\n",
    "        x = torch.cat([vec3,dot,sim],dim=1)\n",
    "        x = self.norm(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "#         x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "\n",
    "#         x = torch.relu(self.fc5(x))\n",
    "        x = torch.sigmoid(self.fc6(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "class NNRecommender(Recommender):\n",
    "    \"\"\"\n",
    "    Linear recommender class based on user and item features.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed=6789, n_neg_per_pos=5):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.model = None\n",
    "        self.n_neg_per_pos = n_neg_per_pos\n",
    "        \n",
    "        self.recommender_df = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        self.users_df = None\n",
    "        self.user_features = None\n",
    "        \n",
    "        self.seed = seed\n",
    "        self.rng = np.random.RandomState(seed=seed)\n",
    "        self.network = None\n",
    "        self.final_std = None\n",
    "        self.final_norm = None\n",
    "        self.model_features = None\n",
    "        self.importance = None\n",
    "        \n",
    "        \n",
    "        \n",
    "    def get_best_features(self,interactions_df,prod_features,k):\n",
    "        selector = SelectKBest(f_regression, k=k)\n",
    "        prod_features_df = interactions_df.loc[:,prod_features+[\"interacted\"]]\n",
    "        y = prod_features_df['interacted'].values\n",
    "\n",
    "        X = prod_features_df.loc[:,prod_features].values\n",
    "\n",
    "        selector.fit(X, y)\n",
    "        \n",
    "        cols = selector.get_support(indices=True)\n",
    "        features_with_scores = sorted([(\"prod\"+str(index),elem) for index,elem in enumerate(selector.scores_) if not math.isnan(elem)],key=lambda x:x[1],reverse=True)[:k]\n",
    "        features_with_scores = {i:v for i,v in features_with_scores}\n",
    "        total = sum(features_with_scores.values())\n",
    "        self.importance = {k:float(v/total) for k,v in features_with_scores.items()}\n",
    "\n",
    "        selected_features_df = prod_features_df.iloc[:,cols]\n",
    "        selected_features = selected_features_df.columns.tolist()\n",
    "\n",
    "        features_df_new = interactions_df.loc[:,selected_features+[\"interacted\"]]\n",
    "\n",
    "        self.model_features = selected_features\n",
    "        return features_df_new\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        \n",
    "        interactions_df = interactions_df.copy()\n",
    "        interactions_df.loc[:,\"interacted\"] = 1\n",
    "        \n",
    "        # Prepare users_df and items_df \n",
    "        # (optional - use only if you want to train a hybrid model with content-based features)\n",
    "        \n",
    "        users_df, user_features = prepare_users_df(interactions_df)\n",
    "        \n",
    "        self.users_df = users_df\n",
    "        self.user_features = user_features\n",
    "        \n",
    "        items_df, item_features = prepare_items_df(interactions_df)\n",
    "        items_df = items_df.loc[:, ['item_id'] + item_features]\n",
    "        \n",
    "        # Generate negative interactions\n",
    "        \n",
    "        # <<<Write your code here>>>\n",
    "        negative_interactions = []\n",
    "        \n",
    "        items_unique = interactions_df.loc[:,\"item_id\"].unique()\n",
    "        users_unique = interactions_df.loc[:,\"user_id\"].unique()\n",
    "\n",
    "        desire=int(self.n_neg_per_pos * len(interactions_df))\n",
    "        hmany=100\n",
    "        rng = np.random.RandomState(seed=6789)\n",
    "        real_interaction = interactions_df.loc[:,[\"user_id\",\"item_id\"]]\n",
    "        length = 0\n",
    "        total_negative_interactions=pd.DataFrame(negative_interactions)\n",
    "        while length!=desire and length<desire :\n",
    "            it = rng.choice(items_unique,hmany)\n",
    "            us = rng.choice(users_unique,hmany)\n",
    "            tmp_negative_interaction = pd.DataFrame({'user_id':us,'item_id':it}).drop_duplicates()\n",
    "\n",
    "            result = pd.merge(tmp_negative_interaction,real_interaction,on=[\"user_id\",\"item_id\"])\n",
    "            if len(result)==0:\n",
    "                total_negative_interactions = pd.concat([total_negative_interactions,tmp_negative_interaction]).drop_duplicates()\n",
    "                length = total_negative_interactions.size\n",
    "\n",
    "        total_negative_interactions = total_negative_interactions.iloc[:desire]\n",
    "        total_negative_interactions.loc[:,'interacted']=0\n",
    "        negative_interactions = total_negative_interactions.to_numpy()\n",
    "#         print(\"neg iter\")\n",
    "#         display(HTML(total_negative_interactions.head(10).to_html()))\n",
    "        \n",
    "        \n",
    "        interactions_df = pd.concat(\n",
    "            [interactions_df, pd.DataFrame(negative_interactions, columns=['user_id', 'item_id', 'interacted'])])\n",
    "        \n",
    "        # Merge user and item features\n",
    "        # (optional - use only if you want to train a hybrid model with content-based features)\n",
    "        \n",
    "        interactions_df = pd.merge(interactions_df, users_df, on=['user_id'])\n",
    "        interactions_df = pd.merge(interactions_df, items_df, on=['item_id'])\n",
    "        \n",
    "#         print(\"Shape \",interactions_df.shape[0])\n",
    "        \n",
    "        \n",
    "        interactions_df = interactions_df.drop_duplicates()\n",
    "#         display(HTML(interactions_df.loc[:,['user_id', 'item_id', 'interacted']].head(20).to_html()))\n",
    "        \n",
    "#         print(\"Shape 2 \",interactions_df.shape[0])\n",
    "        \n",
    "        u_colls = users_df.columns.tolist()\n",
    "        u_colls.remove(\"user_id\")\n",
    "        i_colls = items_df.columns.tolist()\n",
    "        i_colls.remove(\"item_id\")\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "#         prod_cols=[]\n",
    "#             new\n",
    "        prod_cols = u_colls + i_colls\n",
    "\n",
    "#         for index,elem in enumerate(zip(u_colls,i_colls)):\n",
    "\n",
    "#             tmp_result = interactions_df.loc[:,elem[0]] * interactions_df.loc[:,elem[1]]\n",
    "# #             print(\"COLS: \", interactions_df.loc[:,elem[0]],\" :: \",interactions_df.loc[:,elem[1]])\n",
    "# #             tmp_result = interactions_df.loc[:,elem[0]] + interactions_df.loc[:,elem[1]]\n",
    "#             interactions_df.loc[:,\"prod\"+str(index)]=tmp_result\n",
    "#             prod_cols.append(\"prod\"+str(index))\n",
    "            \n",
    "#         print(\"PROD COLS \",u_colls)\n",
    "\n",
    "\n",
    "    \n",
    "        new_interactions_df = interactions_df\n",
    "#         display(HTML(new_interactions_df.head(10).to_html()))\n",
    "        \n",
    "        self.model_features = prod_cols\n",
    "#         print(len(self.model_features))\n",
    "\n",
    "\n",
    "        \n",
    "#         self.final_norm = Normalizer()\n",
    "#         scaled_df = pd.DataFrame(self.final_norm.fit_transform(new_interactions_df.loc[:,self.model_features]),columns=self.model_features)\n",
    "#         self.final_std = StandardScaler()\n",
    "#         scaled_df = pd.DataFrame(self.final_std.fit_transform(scaled_df.loc[:,self.model_features]),columns=self.model_features)\n",
    "#         sec_norm = Normalizer()\n",
    "#         scaled_df = pd.DataFrame(sec_norm.fit_transform(scaled_df.loc[:,self.model_features]),columns=self.model_features)\n",
    "#         scaled_df = new_interactions_df.loc[:,self.model_features]\n",
    "#         scaled_df.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "#         scaled_df = scaled_df.fillna(0)\n",
    "#         print(np.min(scaled_df))\n",
    "        \n",
    "\n",
    "        \n",
    "#         print(scaled_df.isinf())\n",
    "#         display(HTML(scaled_df.head(10).to_html()))\n",
    "#         scaled_df.loc[:,'interacted'] = new_interactions_df['interacted']\n",
    "#         scaled_df = scaled_df.round(2)\n",
    "#         scaled_df.astype('float64')\n",
    "#         display(HTML(scaled_df.head(10).to_html()))\n",
    "\n",
    "#         scaled_df = self.get_best_features(scaled_df,prod_cols,k=11)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        x = new_interactions_df.loc[:,self.model_features]\n",
    "        y = new_interactions_df['interacted'].to_frame()\n",
    "        \n",
    "#         pca = PCA(10)\n",
    "#         pcaed = pca.fit_transform(x,y)\n",
    "#         print(\"X: \",x.dtype)\n",
    "#         display(HTML(pcaed)))\n",
    "        \n",
    "        interaction_ids = self.rng.permutation(len(x))\n",
    "        limit_id = int(0.2*len(interaction_ids))\n",
    "        validation_ids = interaction_ids[:limit_id]\n",
    "        \n",
    "        train_ids = interaction_ids[limit_id:]\n",
    "#         print(validation_ids)\n",
    "#         print(train_ids)\n",
    "        \n",
    "#         print(len(validation_ids))\n",
    "        \n",
    "#         display(HTML(x.iloc[validation_ids].head(10).to_html()))\n",
    "#         print(torch.from_numpy(x.iloc[train_ids].to_numpy()))\n",
    "#         x_train = []\n",
    "#         for index,data in x.iloc[train_ids].iterrows():\n",
    "#             tmp_df = data.to_frame().transpose()\n",
    "# #             display(HTML(tmp_df.to_html()))\n",
    "#             x1 = torch.tensor(tmp_df.loc[:,u_colls].to_numpy()).float()\n",
    "#             x2 = torch.tensor(tmp_df.loc[:,i_colls].to_numpy()).float()\n",
    "#             x_train.append([x1,x2])\n",
    "#         x_train = torch.stack(x_train,dim=0)\n",
    "#         print(\"x_Train \",x_train)\n",
    "#         x_train = torch.tensor(x.iloc[train_ids].to_numpy()).float()\n",
    "#         x_train = torch.tensor([(x.iloc[train_ids].loc[:,u_colls].to_numpy()),(x.iloc[train_ids].loc[:,i_colls].to_numpy())]).float()\n",
    "#         y_train = torch.tensor(y.iloc[train_ids].to_numpy()).float()\n",
    "#         x_val= torch.tensor([(x.iloc[validation_ids].loc[:,u_colls].to_numpy()),(x.iloc[validation_ids].loc[:,i_colls].to_numpy())]).float()\n",
    "# # #         torch.tensor(x.iloc[validation_ids].to_numpy()).float()\n",
    "#         y_val = torch.tensor(y.iloc[validation_ids].to_numpy()).float()\n",
    "        \n",
    "        x_train = torch.tensor([(x.loc[:,u_colls].to_numpy()),(x.loc[:,i_colls].to_numpy())]).float()\n",
    "        y_train = torch.tensor(y.to_numpy()).float()\n",
    "        \n",
    "#         print(x_val.shape[0])\n",
    "\n",
    "        # Initialize the neural network model\n",
    "        print(x_train.shape[1])\n",
    "        \n",
    "#         # <<<Write your code here>>>\n",
    "        self.network = MyNetwork(27,16,6789)\n",
    "        \n",
    "#         self.optimizer = optim.Adam(self.network.parameters(),lr = 0.00001)\n",
    "#         self.optimizer = optim.SGD(self.network.parameters(),lr = 0.000173)     \n",
    "#         self.optimizer = optim.SGD(self.network.parameters(),lr = 0.00001) \n",
    "        self.optimizer = optim.Adadelta(self.network.parameters(),lr=0.007) \n",
    "        \n",
    "        # Train the model using an optimizer\n",
    "#         epochs = 2000\n",
    "#         epochs = 200\n",
    "#         batch_size = 4100\n",
    "        min_loss = 100\n",
    "        epochs = 300\n",
    "#         batch_size = int((x_train.shape[1]/64)+1)\n",
    "        batch_size = 512\n",
    "        n_batches = int(np.ceil((x_train.shape[1])/batch_size))\n",
    "        for epoch in range(epochs):\n",
    "            for batch in range(n_batches):\n",
    "#                 print(\"Epoch: \",epoch,\" Batch: \",batch)\n",
    "                x_tmp = x_train[:,(batch*batch_size):((batch+1)*batch_size),:]\n",
    "                y_tmp = y_train[(batch*batch_size):((batch+1)*batch_size) ]\n",
    "                self.network.train()\n",
    "                self.optimizer.zero_grad()\n",
    "#                 print(x_tmp.dtype)\n",
    "                y_hat_train = self.network(x_tmp).clip(0.000001, 0.999999)\n",
    "#                 y_hat_train = y_hat_train[:,:]\n",
    "#                 print(y_hat_train)\n",
    "                loss = - ((y_tmp * y_hat_train.log()) + ((1 - y_tmp) * (1-y_hat_train).log())).sum()\n",
    "#                 print(epoch,\" :: train \",loss)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "#                 self.network.eval()\n",
    "#                 with torch.no_grad():\n",
    "                    \n",
    "#                     y_hat_val = self.network(x_val).clip(0.000001, 0.999999)\n",
    "# #                     print(\"RESULTS: \",torch.cat([y_val,y_hat_val,(y_val-y_hat_val).abs()],dim=1))\n",
    "#                     print(\"MAX: \",torch.where((y_val-y_hat_val).abs()>0.5,1.0,0.0).sum())\n",
    "# #                     print(\"MAX V: \",(y_val-y_hat_val).abs().max())\n",
    "#                     loss_val = - ((y_val * y_hat_val.log()) + ((1 - y_val) * (1-y_hat_val).log()) ).sum()\n",
    "#                     if min_loss>loss_val.item():\n",
    "#                         min_loss = loss_val.item()\n",
    "# #                         torch.save(self.network.state_dict(), \"./best_model_save\")\n",
    "#                     print(epoch,\" :: \",loss_val)\n",
    "#                     print(\"y diff \",torch.cat([y_val,y_hat_val],axis=1))\n",
    "                \n",
    "            \n",
    "        \n",
    "        # <<<Write your code here>>>\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        # Clean previous recommendations (iloc could be used alternatively)\n",
    "        self.recommender_df = self.recommender_df[:0]\n",
    "        \n",
    "        # Prepare users_df and items_df\n",
    "        # (optional - use only if you want to train a hybrid model with content-based features)\n",
    "        \n",
    "        users_df = users_df.loc[:, 'user_id']\n",
    "        users_df = pd.merge(users_df, self.users_df, on=['user_id'], how='left').fillna(0)\n",
    "#         display(HTML(users_df.head(10).to_html()))\n",
    "        \n",
    "        items_df, item_features = prepare_items_df(items_df)\n",
    "        items_df = items_df.loc[:, ['item_id'] + item_features]\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Score the items\n",
    "    \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "#         print(\"users\")\n",
    "#         display(HTML(users_df.head(10).to_html()))\n",
    "        for ix, user in users_df.iterrows():\n",
    "            \n",
    "            # Calculate the score for the user and every item in items_df\n",
    "            interactions_df = pd.merge(user.to_frame().transpose(),items_df,how=\"cross\")\n",
    "            \n",
    "#             print(\"interactions_df\")\n",
    "#             display(HTML(interactions_df.head(10).to_html()))\n",
    "            \n",
    "            u_colls = users_df.columns.tolist()\n",
    "            u_colls.remove(\"user_id\")\n",
    "            i_colls = items_df.columns.tolist()\n",
    "            i_colls.remove(\"item_id\")\n",
    "\n",
    "\n",
    "            prod_cols=[]\n",
    "\n",
    "#             for index,elem in enumerate(zip(u_colls,i_colls)):\n",
    "\n",
    "#                 tmp_result = interactions_df.loc[:,elem[0]] * interactions_df.loc[:,elem[1]]\n",
    "#                 interactions_df.loc[:,\"prod\"+str(index)]=tmp_result\n",
    "#                 prod_cols.append(\"prod\"+str(index))\n",
    "\n",
    "            interactions_df = interactions_df.fillna(0)\n",
    "\n",
    "            scaled_df = interactions_df.loc[:,self.model_features]\n",
    "            \n",
    "#             print(\"new_interactions_df\")\n",
    "#             display(HTML(new_interactions_df.head(10).to_html()))\n",
    "\n",
    "#             scaled_df = pd.DataFrame(self.final_norm.transform(new_interactions_df.loc[:,self.model_features]),columns=self.model_features)            \n",
    "#             scaled_df = pd.DataFrame(self.final_std.transform(scaled_df.loc[:,self.model_features]),columns=self.model_features)\n",
    "\n",
    "            x = scaled_df.loc[:,self.model_features]\n",
    "            x_test = torch.tensor([(x.loc[:,u_colls].to_numpy()),(x.loc[:,i_colls].to_numpy())]).float()\n",
    "            \n",
    "            \n",
    "#             x_test = torch.tensor(x.to_numpy()).float()\n",
    "#             self.network.load_state_dict(torch.load(\"./best_model_save\"))\n",
    "            self.network.eval()\n",
    "            with torch.no_grad():\n",
    "                out = self.network(x_test)\n",
    "#             print(\"out\")\n",
    "#             display(HTML(out.head(20).to_html()))\n",
    "            \n",
    "            scores = out.squeeze().numpy()\n",
    "#             print((scores))\n",
    "#             scores = []\n",
    "#             arr = np.array([0.49140155, 0.86761564, 0.22462055, 0.62140334, 0.01714047])\n",
    "            chosen_ids = np.argsort(-scores)[:n_recommendations].tolist()\n",
    "#             print(\"Chosen \",chosen_ids)\n",
    "#             scores = scores.squeeze().tolist()\n",
    "            scores = scores.tolist()\n",
    "#             print(\"Scores \",scores)\n",
    "            \n",
    "            recommendations = []\n",
    "            for item_id in chosen_ids:\n",
    "#                 print(item_id)\n",
    "                recommendations.append(\n",
    "                    {\n",
    "                        'user_id': user['user_id'],\n",
    "                        'item_id': item_id,\n",
    "                        'score': scores[item_id]\n",
    "                    }\n",
    "                )\n",
    "            user_recommendations = pd.DataFrame(recommendations)\n",
    "\n",
    "            self.recommender_df = pd.concat([self.recommender_df, user_recommendations])\n",
    "\n",
    "        return self.recommender_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-rental",
   "metadata": {},
   "source": [
    "# Quick test of the recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "pacific-friendly",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df = interactions_df.loc[:, ['item_id'] + base_item_features].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "vanilla-exhibition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55952\n"
     ]
    }
   ],
   "source": [
    "# Fit method\n",
    "nn_recommender = NNRecommender()\n",
    "nn_recommender.fit(interactions_df, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "level-messaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>term</th>\n",
       "      <th>length_of_stay_bucket</th>\n",
       "      <th>rate_plan</th>\n",
       "      <th>room_segment</th>\n",
       "      <th>n_people_bucket</th>\n",
       "      <th>weekend_stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>0.998087</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.998164</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>103</td>\n",
       "      <td>0.998173</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>98</td>\n",
       "      <td>0.998182</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.998438</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.998478</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>108</td>\n",
       "      <td>0.998976</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.999030</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>102</td>\n",
       "      <td>0.999176</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>0.999179</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.875453</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.0</td>\n",
       "      <td>208</td>\n",
       "      <td>0.877290</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.0</td>\n",
       "      <td>703</td>\n",
       "      <td>0.882108</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.891943</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>87</td>\n",
       "      <td>0.912659</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.0</td>\n",
       "      <td>68</td>\n",
       "      <td>0.931308</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0.937302</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0</td>\n",
       "      <td>159</td>\n",
       "      <td>0.957535</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.996633</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998964</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.880896</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.0</td>\n",
       "      <td>87</td>\n",
       "      <td>0.907199</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.0</td>\n",
       "      <td>73</td>\n",
       "      <td>0.907681</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0.916901</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3.0</td>\n",
       "      <td>56</td>\n",
       "      <td>0.947676</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.954910</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.0</td>\n",
       "      <td>279</td>\n",
       "      <td>0.968195</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3.0</td>\n",
       "      <td>174</td>\n",
       "      <td>0.974621</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.0</td>\n",
       "      <td>168</td>\n",
       "      <td>0.978921</td>\n",
       "      <td>HighSeason</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999385</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0.728870</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.0</td>\n",
       "      <td>51</td>\n",
       "      <td>0.805566</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[5-inf]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.0</td>\n",
       "      <td>54</td>\n",
       "      <td>0.866459</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.873128</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4.0</td>\n",
       "      <td>16</td>\n",
       "      <td>0.877167</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.0</td>\n",
       "      <td>687</td>\n",
       "      <td>0.884128</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.921556</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4.0</td>\n",
       "      <td>170</td>\n",
       "      <td>0.929626</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.0</td>\n",
       "      <td>77</td>\n",
       "      <td>0.990567</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.998330</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.0</td>\n",
       "      <td>687</td>\n",
       "      <td>0.366598</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.486824</td>\n",
       "      <td>OffSeason</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.0</td>\n",
       "      <td>77</td>\n",
       "      <td>0.530466</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[3-4]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.0</td>\n",
       "      <td>497</td>\n",
       "      <td>0.589862</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Nonref</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5.0</td>\n",
       "      <td>89</td>\n",
       "      <td>0.606478</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.0</td>\n",
       "      <td>565</td>\n",
       "      <td>0.665710</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[260-360]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.0</td>\n",
       "      <td>133</td>\n",
       "      <td>0.668636</td>\n",
       "      <td>LowSeason</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5.0</td>\n",
       "      <td>87</td>\n",
       "      <td>0.757920</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[2-3]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0.829556</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[160-260]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.989378</td>\n",
       "      <td>WinterVacation</td>\n",
       "      <td>[4-7]</td>\n",
       "      <td>Standard</td>\n",
       "      <td>[0-160]</td>\n",
       "      <td>[2-2]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Recommender method\n",
    "\n",
    "recommendations = nn_recommender.recommend(pd.DataFrame([[1], [2], [3], [4], [5]], columns=['user_id']), items_df, 10)\n",
    "\n",
    "recommendations = pd.merge(recommendations, items_df, on='item_id', how='left')\n",
    "display(HTML(recommendations.sort_values(by=[\"user_id\",\"score\"],ascending=True).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-proportion",
   "metadata": {},
   "source": [
    "# Tuning method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "alive-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation_and_testing.testing import evaluate_train_test_split_implicit\n",
    "\n",
    "seed = 6789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "residential-defeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "import traceback\n",
    "\n",
    "def tune_recommender(recommender_class, interactions_df, items_df, \n",
    "                     param_space, max_evals=1, show_progressbar=True, seed=6789):\n",
    "    # Split into train_validation and test sets\n",
    "\n",
    "    shuffle = np.arange(len(interactions_df))\n",
    "    rng = np.random.RandomState(seed=seed)\n",
    "    rng.shuffle(shuffle)\n",
    "    shuffle = list(shuffle)\n",
    "\n",
    "    train_test_split = 0.8\n",
    "    split_index = int(len(interactions_df) * train_test_split)\n",
    "\n",
    "    train_validation = interactions_df.iloc[shuffle[:split_index]]\n",
    "    test = interactions_df.iloc[shuffle[split_index:]]\n",
    "\n",
    "    # Tune\n",
    "\n",
    "    def loss(tuned_params):\n",
    "        recommender = recommender_class(seed=seed, **tuned_params)\n",
    "        hr1, hr3, hr5, hr10, ndcg1, ndcg3, ndcg5, ndcg10 = evaluate_train_test_split_implicit(\n",
    "            recommender, train_validation, items_df, seed=seed)\n",
    "        return -hr10\n",
    "\n",
    "    n_tries = 1\n",
    "    succeded = False\n",
    "    try_id = 0\n",
    "    while not succeded and try_id < n_tries:\n",
    "        try:\n",
    "            trials = Trials()\n",
    "            best_param_set = fmin(loss, space=param_space, algo=tpe.suggest, \n",
    "                                  max_evals=max_evals, show_progressbar=show_progressbar, trials=trials, verbose=True)\n",
    "            succeded = True\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            try_id += 1\n",
    "            \n",
    "    if not succeded:\n",
    "        return None\n",
    "        \n",
    "    # Validate\n",
    "    \n",
    "    recommender = recommender_class(seed=seed, **best_param_set)\n",
    "\n",
    "    results = [[recommender_class.__name__] + list(evaluate_train_test_split_implicit(\n",
    "        recommender, {'train': train_validation, 'test': test}, items_df, seed=seed))]\n",
    "\n",
    "    results = pd.DataFrame(results, \n",
    "                           columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "    display(HTML(results.to_html()))\n",
    "    \n",
    "    return best_param_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-electronics",
   "metadata": {},
   "source": [
    "## Tuning of the recommender\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Tune your model using the code below. You only need to put the class name of your recommender and choose an appropriate parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_space = {\n",
    "#     'n_neg_per_pos': hp.quniform('n_neg_per_pos', 1, 2, 1)\n",
    "# }\n",
    "\n",
    "# best_param_set = tune_recommender(NNRecommender, interactions_df, items_df,\n",
    "#                                   param_space, max_evals=1, show_progressbar=True, seed=seed)\n",
    "best_param_set = tune_recommender(NNRecommender, interactions_df, items_df,\n",
    "                                  None, max_evals=1, show_progressbar=True, seed=seed)\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(best_param_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-cholesterol",
   "metadata": {},
   "source": [
    "# Final evaluation\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Run the final evaluation of your recommender and present its results against the Amazon and Netflix recommenders' results. You just need to give the class name of your recommender and its tuned parameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "quantitative-nurse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NNRecommender</td>\n",
       "      <td>0.019743</td>\n",
       "      <td>0.030931</td>\n",
       "      <td>0.042777</td>\n",
       "      <td>0.058243</td>\n",
       "      <td>0.019743</td>\n",
       "      <td>0.026113</td>\n",
       "      <td>0.030984</td>\n",
       "      <td>0.035953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_recommender = NNRecommender(n_neg_per_pos=2)  # Initialize your recommender here\n",
    "# nn_recommender.fit(interactions_df, None, None)\n",
    "# Give the name of your recommender in the line below\n",
    "nn_tts_results = [['NNRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    nn_recommender, interactions_df, items_df))]\n",
    "\n",
    "nn_tts_results = pd.DataFrame(\n",
    "    nn_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(nn_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-reynolds",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.amazon_recommender import AmazonRecommender\n",
    "\n",
    "amazon_recommender = AmazonRecommender()\n",
    "\n",
    "amazon_tts_results = [['AmazonRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    amazon_recommender, interactions_df, items_df))]\n",
    "\n",
    "amazon_tts_results = pd.DataFrame(\n",
    "    amazon_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(amazon_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.netflix_recommender import NetflixRecommender\n",
    "\n",
    "netflix_recommender = NetflixRecommender(n_epochs=30, print_type='live')\n",
    "\n",
    "netflix_tts_results = [['NetflixRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    netflix_recommender, interactions_df, items_df))]\n",
    "\n",
    "netflix_tts_results = pd.DataFrame(\n",
    "    netflix_tts_results, columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(netflix_tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts_results = pd.concat([nn_tts_results, amazon_tts_results, netflix_tts_results]).reset_index(drop=True)\n",
    "display(HTML(tts_results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-calvin",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "<span style=\"color:red\"><font size=\"4\">**Task:**</font></span><br> \n",
    "Write a summary of your experiments. What worked well and what did not? What are your thoughts how could you possibly further improve the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-heavy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
